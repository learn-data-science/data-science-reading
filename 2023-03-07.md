## Chosen Paper
* [High-throughput Generative Inference of Large Language Models with a Single GPU](https://arxiv.org/abs/2205.11558](https://github.com/FMInference/FlexGen/blob/f5fbfe66a6a1637935243f2e40a95e7b7dbca213/docs/paper.pdf): 
  Ying Sheng, Lianmin Zheng, Binhang Yuan, Zhuohan Li, Max Ryabinin, Beidi Chen, Percy Liang, Christopher Re, Ion Stoica, Ce Zhang; 
  
* Supplementary Materials:
    * Related Code: https://github.com/FMInference/FlexGen



